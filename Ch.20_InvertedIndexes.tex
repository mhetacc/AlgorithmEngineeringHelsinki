\chapter{Inverted Indexes\label{invindex}}

Most of the information present in this chapter is thanks to Mahapatra and Biswas "Inverted indexes: Types and techniques" \citep{fromDocToIndex}. 

What we will need for the algorithms presented in the rest of this documents are inverted indexes (also called posting lists). To get them we first need to process documents into lists of words (called \textit{word tokens}), then for each token compute a list of \verb+IDs+ that refer to the documents which contain that specific token. Let's see each step in order.

\section{Document Pre-Processing}

Documents go through a series of processing steps before being indexed: they get converted into token in the lexing phase, which are then possibly normalized, stemmed or even pruned (removed) entirely.

\subsection{Lexing}

\begin{wrapfigure}{r}{0.5\textwidth} %this figure will be at the right
    \centering
    \includegraphics[width=.5\textwidth]{imgs/lorem_lexing.png}
    \caption{Lexing: from text to word tokens\label{fig:lorem_lexing}}
\end{wrapfigure}

The process of transforming a document into a list of tokens, each of which is a single word, si called \textit{lexing} \ref{fig:lorem_lexing}. There often is a maximum length for a single token, as to prevent unbounded index growth in edge cases, and all input is generally first converted into lower-case to normalize it. All non-punctuation characters are added to the list of tokens one by one, and those that exceed a certain size are often pruned (removed from the corpus). It is not entirely clear how Google and other big companies do this step, and it certainly feels strange to think they employ a simple \textit{brute force}, single scan approach, but as mentioned before it is not easy to find information about it. \\
All of the above works only with alphabetic languages, ideographic ones (e.g., Chinese) need specialized search techniques. 

\subsection{Stemming}

We can consider this step deprecated, since nowadays memory, especially for things like text and arrays (which inverted index basically are), is cheap and bountiful. \\
The idea is to find a sort of \textit{root} (stem) of the words, and indexing that instead. To make an example: fishnet, fishery, fishing, fishy, fishmonger, can all be boiled down to their stem \textit{fish} \ref{fig:fishstem}. 

\begin{figure}[ht] 
\begin{center}
\includegraphics[width=.8\textwidth]{imgs/stemming.png}
\caption{Stemming to stem "fish"\label{fig:fishstem}}
\end{center}
\end{figure}

In the example above should be clear already that stemming carry some problems: a user searching for "fishnet" is likely not shopping for fishing equipment, thus most modern search engine skip this normalizing step, and most stemming algorithms (most famous of which is Porter's) are complex, full of exceptions and exceptions to the exceptions, while still failing to unite together the correct words. This step basically reduces query precision while providing very little in return.

\subsection{Stop Words}

\textit{Stop words} are words that work as connectives of sorts, like \textit{and}, \textit{the}, \textit{is}, \textit{of}, \textit{to}, etc. \\
Their quantity is language dependent (e.g., in English they could be around 500 words) and they are often removed from the corpus which, for normal queries, does not worsen the results while saving space in the index. However in some cases like searching for \textit{to be or not to be} stop words are actually essential, and removing them would make the search fail. \\ 

\begin{wrapfigure}{r}{0.5\textwidth} %this figure will be at the right
    \centering
    \includegraphics[width=.4\textwidth]{imgs/stopwords.png}
    \caption{Stop words pruning\label{fig:stopwords}}
\end{wrapfigure}

Thankfully they are so common that if saved as differences between consecutive different values, both their document number and word position lists can be compressed to save space. Because of this, the overhead is not as big as one might think, thus modern search engines (like Google) do not seem to remove them from the index, since doing so put them at a competitive advantage at the expense of a slightly bigger index. \\ 

\section{Inverted Indexes}

Now that we have a set of word tokens, we can start building our inverted indexes (or posting lists): documents are often stored as lists of words, but we invert (hence the name) this concept by storing for each word the list of documents that contain it. There are several variants of this data structure, but at minimum you need to store for each word the list of documents that contain that specific word. \\
We can change the granularity by adding the frequency of the word in the document, which can be useful for query optimization, or by adding the word position in the document, allowing for in-document queries.\\
Space used by inverted indexes varies wildly in the range of five to one hundred percent (5-100\%) of the total size of the document indexed, and this is because implementations come in many different variations: some store word positions and some don't, some aggressively pre-process documents and some don't, some dynamically update themselves and some don't, some use complex and powerful compression methods and some don't, and so on. 

Table \ref{tab:sample_docs} show some sample documents, while table \ref{tab:inverted_lists} shows some examples of inverted indexes, with different levels of granularity.

\begin{table}[ht]
    \begin{center}
        \begin{tabularx}{\textwidth}{|c|X|}
            \hline
            \textbf{ID} & \multicolumn{1}{c|}{\textbf{Contents}}  \\ \hline
            1 & The only way not to think about money is to have a great deal of it \\ \hline
            2 & When I was young I thought that money was the most important thing in life; now that I am old I know that it is. \\ \hline
            3 & A man is usually more careful of money than he is of his principles.\\ \hline
        \end{tabularx}
        \caption{Sample document collection\label{tab:sample_docs}}
    \end{center}
\end{table}

\begin{table}[ht]
    \begin{center}
        \begin{tabular}{|c|c|c|c|}
            \hline
            \textbf{Word} & \textbf{Doc List} & \textbf{Frequency} & \textbf{Positions} \\ \hline
            a & 1, 3 & 1:1, 3:1 & 1:(12), 3:(1) \\ \hline
            About & 1 & 1:1 & 1:(7) \\ \hline
            am & 2 & 2:1 & 2:(19) \\ \hline
            Careful & 3 & 3:1 & 3:(6) \\ \hline
            deal & 1 & 1:1 & 1:(16) \\ \hline
            great & 1 & 1:1 & 1:(13) \\ \hline
            have & 1 & 1:1 & 1:(11) \\ \hline
            ... & ... & ... & ... \\ \hline
            money & 1, 2, 3 & 1:2, 2:1, 3:1 & 1:(8), 2:(8), 3:(9) \\ \hline
            more & 3 & 3:1 & 3:(5) \\ \hline
            ... & ... & ... & ... \\ \hline
            when & 2 & 2:1 & 2:(1) \\ \hline
        \end{tabular}
        \caption{Inverted lists example, most words omitted\label{tab:inverted_lists}} 
    \end{center}
\end{table}


